services:
  rustfs:
    image: rustfs/rustfs:latest
    restart: unless-stopped
    environment:
      RUSTFS_VOLUMES: /data
      RUSTFS_ADDRESS: '0.0.0.0:9000'
      RUSTFS_CONSOLE_ADDRESS: '0.0.0.0:9001'
      RUSTFS_CONSOLE_ENABLE: 'true'
      RUSTFS_ACCESS_KEY: rustfsuser
      RUSTFS_SECRET_KEY: rustfspassword
    ports:
      - '8999:9000' # 9000 is taken by clickhouse, map to 8999
      - '9001:9001' # web console
    volumes:
      - rustfs:/data
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:9000/health"]
      interval: 5s
      timeout: 5s
      retries: 5
  rustfs-init:
    image: minio/mc:latest
    restart: on-failure  # run once and exit
    entrypoint: >
      /bin/sh -c "
      sleep 2;
      until mc alias set local http://rustfs:9000 $$RUSTFS_ACCESS_KEY $$RUSTFS_SECRET_KEY; do echo waiting for rustfs...; sleep 1; done;
      mc mb --ignore-existing local/bucket1;
      exit 0;
      "
    environment:
      RUSTFS_ACCESS_KEY: rustfsuser
      RUSTFS_SECRET_KEY: rustfspassword
    depends_on:
      rustfs:
        condition: service_healthy
  ice-rest-catalog:
    image: altinity/ice-rest-catalog:latest
    restart: unless-stopped
    ports:
      - '5001:5000'
    configs:
      - source: ice-rest-catalog-yaml
        target: /etc/ice/ice-rest-catalog.yaml
    volumes:
      - ./data/docker-compose/ice-rest-catalog/var/lib/ice-rest-catalog:/var/lib/ice-rest-catalog
    depends_on:
      - rustfs-init
  clickhouse:
    image: altinity/clickhouse-server:25.8.12.20747.altinityantalya-alpine
    restart: unless-stopped
    environment:
      CLICKHOUSE_SKIP_USER_SETUP: "1" # insecure
    ports:
      - "8123:8123" # clickhouse/http
      - "9000:9000" # clickhouse/native
    configs:
      - source: clickhouse-init
        target: /docker-entrypoint-initdb.d/init-db.sh
    volumes:
      - ./data/docker-compose/clickhouse/var/log/clickhouse-server:/var/log/clickhouse-server
    depends_on:
      - ice-rest-catalog
  ice:
    image: altinity/ice:${ICE_TAG:-latest}
    pull_policy: ${ICE_PULL_POLICY:-always}
    configs:
      - source: ice-yaml
        target: /app/.ice.yaml
    working_dir: /app
    depends_on:
      - ice-rest-catalog
    profiles:
      - tools
  otlp2parquet:
    image: ghcr.io/smithclay/otlp2parquet:latest
    restart: unless-stopped
    ports:
      - '4318:4318' # OTLP/HTTP
    environment:
      OTLP2PARQUET_STORAGE_BACKEND: s3
      OTLP2PARQUET_S3_BUCKET: bucket1
      OTLP2PARQUET_S3_ENDPOINT: http://rustfs:9000
      OTLP2PARQUET_S3_REGION: us-east-1
      OTLP2PARQUET_CATALOG_MODE: iceberg
      OTLP2PARQUET_ICEBERG_REST_URI: http://ice-rest-catalog:5000
      OTLP2PARQUET_ICEBERG_WAREHOUSE: s3://bucket1
      AWS_ACCESS_KEY_ID: rustfsuser
      AWS_SECRET_ACCESS_KEY: rustfspassword
    depends_on:
      - ice-rest-catalog
configs:
  clickhouse-init:
    content: |
      #!/bin/bash
      clickhouse client --query "
        CREATE OR REPLACE VIEW otel_logs AS
        SELECT * FROM s3('http://rustfs:9000/bucket1/otlp/otel_logs/data/*.parquet', 'rustfsuser', 'rustfspassword', 'Parquet');
      " || true
      echo "ClickHouse initialized (otel_logs view will work once data is ingested)"
  ice-rest-catalog-yaml:
    content: |
      uri: jdbc:sqlite:file:/var/lib/ice-rest-catalog/db.sqlite?journal_mode=WAL&synchronous=OFF&journal_size_limit=500
      warehouse: s3://bucket1
      s3:
        endpoint: http://rustfs:9000
        pathStyleAccess: true
        accessKeyID: rustfsuser
        secretAccessKey: rustfspassword
        region: us-east-1
      anonymousAccess:
        enabled: true
        accessConfig:
          readOnly: false
  ice-yaml:
    content: |
      uri: http://ice-rest-catalog:5000
      s3:
        endpoint: http://rustfs:9000
        accessKeyID: rustfsuser
        secretAccessKey: rustfspassword
volumes:
  rustfs:
